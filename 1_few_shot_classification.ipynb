{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb24ae43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\AppData\\Local\\Temp\\ipykernel_7712\\3247020590.py:1: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(\"../../data/cleaned-facebook-data-2024-12-02.csv\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33979"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import gc\n",
    "import torch\n",
    "import math\n",
    "import scipy.stats as st\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, set_seed, BitsAndBytesConfig\n",
    "from auto_gptq import AutoGPTQForCausalLM\n",
    "from transformers import GPTQConfig\n",
    "import os\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM, \n",
    "    AutoTokenizer, \n",
    "    pipeline,\n",
    "    GPTQConfig,\n",
    "    set_seed,\n",
    "AwqConfig\n",
    ")\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb1cff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../../data/cleaned-facebook-data-2024-12-02.csv\")\n",
    "df = df.dropna(subset=['text']).reset_index(drop=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bac5c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def instantiate_pipeline_qwen(\n",
    "    access_token=\"<Input access token>\",\n",
    "    model_id=\"Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4\"\n",
    "):\n",
    "    set_seed(42)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_id,\n",
    "        token=access_token,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    if tokenizer.pad_token_id is None:\n",
    "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    print(\"Loading GPTQ model... (this may take a while)\")\n",
    "    \n",
    "    # Configure GPTQ settings\n",
    "    gptq_config = GPTQConfig(\n",
    "        bits=4,\n",
    "        use_exllama=False,  # Disable exllama to avoid compatibility issues\n",
    "        disable_exllama=True\n",
    "    )\n",
    "    \n",
    "    # Load the model with explicit GPTQ configuration\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.float16,  # Use float16 instead of auto\n",
    "        trust_remote_code=True,\n",
    "        token=access_token,\n",
    "        quantization_config=gptq_config,\n",
    "        low_cpu_mem_usage=True,  # This helps with memory management\n",
    "        offload_buffers=True  # This helps avoid the meta device issue\n",
    "    )\n",
    "\n",
    "    pipe = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        return_full_text=False,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    print(f\"✅ Pipeline instantiated for {model_id}!\")\n",
    "    return pipe\n",
    "\n",
    "\n",
    "def classifier_qwen(text, pipe):\n",
    "    '''\n",
    "    Generates topic model labels from the provided topic model's keywords (topic_modeling_keywords) \n",
    "    with few-shot in-context learning using either llama or phi pre-trained model.\n",
    "    \n",
    "    Parameters:\n",
    "    - text (str; required): The social media post to be classified.\n",
    "    - pipe (object; required): The pipeline of an instantiated pre-trained model used.\n",
    "    \n",
    "    Returns:\n",
    "    str: Labels of topic models with explanation and reasoning.\n",
    "    '''\n",
    "    system_message = '''You are a communication expert analyzing Facebook posts from various online community health networks. \n",
    "    These networks consist of organizations, agencies, or groups, and the posts may or may not include health-related content. \n",
    "    Your task is to classify each post based on its primary focus within the context of communication. \n",
    "    This classification will help identify the distinct communication strategies employed across these networks.\n",
    "    '''\n",
    "\n",
    "    task_prompt = '''Classify the given Facebook post from an organization, agency, or group within an online community health network \n",
    "    based on its primary focus in communication. Choose one of the following categories:\n",
    "\n",
    "    1. Individual Behavior: Posts focused on behaviors or actions that affect a person's physical, mental, emotional, or social well-being. \n",
    "    This includes posts promoting individual actions, personal practices or tips, lifestyle changes, and messaging strategies aimed \n",
    "    at fostering behavior modifications for physical, mental, emotional, or social well-being..\n",
    "\n",
    "    2. Policy or Environmental Approaches: Posts addressing policy initiatives or actions, such as laws, legislation, ordinances, \n",
    "    mandates, regulations, or rules. This also includes posts advocating for civic engagement, addressing the built environment, \n",
    "    or discussing economic or social surroundings.\n",
    "\n",
    "    3. Other Organizational or Program/Service Information: Posts that share updates, resources, or services provided by the \n",
    "    organization or program, or that do not fall into \"Individual Behavior\" or \"Policy or Environmental Approaches.\" This category \n",
    "    could include: \n",
    "        (1) promotion of the organization's services, events, or campaigns that do not include any behavioral component or action (No 1.), \n",
    "        (2) staff, volunteer, or partner spotlights, shout-outs, or appreciation posts, or \n",
    "        (3) success stories or stories highlighting the impact of a program or service.\n",
    "\n",
    "    4. Irrelevant: Posts that do not fit any of the above categories. This includes season's greetings, holiday or observance recognition with no elements of No 1., No 2., or No 3.\n",
    "\n",
    "    Strictly return the category number only (1, 2, 3, or 4). Below are examples to guide your classification.\n",
    "    '''\n",
    "\n",
    "    # Few-shot learning examples (unchanged)\n",
    "    Example_1 = '''Did you know? 16% of teens have sustained Noise-Induced Hearing Loss due to prolonged exposure to personal listening devices. Adjust the noise level on your device to protect your hearing. On #WorldHearingDay, let's bring awareness to promoting ear & hearing care. Ear Peace Foundation'''\n",
    "    output_1 = '1'\n",
    "    \n",
    "    Example_2 = '''Families, on Aug. 29, Miami-Dade County Mayor Daniella Levine Cava announced the HOMES Plan, which includes a full suite of programs that will provide relief to struggling homeowners and renters, create more housing people can afford by bringing new units online in the immediate short term and building new units, and preserve and enhance existing affordable housing. Find out more: '''\n",
    "    output_2 = '2'\n",
    "    \n",
    "    Example_3 = '''According to the American Diabetes Association, 1.5 million people will be diagnosed with diabetes this year. If you have diabetes, let us help you manage and balance your health. We can provide support to all of your health care needs.'''\n",
    "    output_3 = '3'\n",
    "\n",
    "    Example_4='''-\tDuring National Nutrition Month and beyond, choose delicious and nutrient-rich foods from each of the five basic food groups! If you want more information about your nutrition, schedule an appointment with one of our CHI Health registered dietitians: https://spr.ly/6182KlG9u.'''\n",
    "    output_4='1'\n",
    "\n",
    "    Example_5 = '''Trust President & CEO James R. Haj encourages support of our early child care educators this #TeacherAppreciationWeek. You can read his letter to editor in Miami's Community Newspapers here https://bit.ly/3KMbgdS #TeacherAppreciationWeek'''\n",
    "    output_5 = \"2\"\n",
    "\n",
    "    Example_6 = '''Today, we are spotlighting our friends at Girl Scouts Louisiana East who hosted their Believe in Girls (B.I.G.) event in April. The event was held at SE LA University and focused on STEM and hands-on experiences for 350 total Girl Scouts. This event was part of our Project-Based grants in 2021. We are grateful for partners like GSLE! #LiveUnited'''\n",
    "    output_6 = '3'\n",
    "\n",
    "\n",
    "\n",
    "    Example_7='''August is Summer Sun Safety Month! With the sun in full force, be mindful of its damaging effects and protect your skin from its harmful rays. Remember that sunscreen is your friend, so apply it often! #buildingbetterhabits #yourbestself #FLIPANY'''\n",
    "    output_7='1'\n",
    "\n",
    "    Example_8='''Governor Parsonâ€™s Supply Chain Task Force published its draft report today opening the public comment period. https://www.modot.org/supplychaintaskforce\n",
    "    This report includes supply chain information, the task forceâ€™s findings, and recommended next steps for Missouri. The focus of the report is infrastructure needs and support for workforce to mitigate and minimize the impacts of supply chain challenges.\n",
    "    Public comments will be received through June 17.'''\n",
    "    output_8=\"2\"\n",
    "\n",
    "\n",
    "\n",
    "    Example_9='''We have a new blog, and it is a part of our Your Dollars at Work campaign! Read about our longtime partner Catholic Charities Diocese of Baton Rouge and how the ALICE Grant they received impacted their clients! Link: https://www.cauw.org/blog/your-dollars-work-impact-story-0 #LiveUnited'''\n",
    "    output_9=\"3\"\n",
    "\n",
    "    Example_10='''-\tQuick, easy, convenient and potentially life-saving. Schedule your free cancer screening today. View all upcoming screenings: https://bit.ly/3pEgReE Screening snapshot this week:\n",
    "    Monroe - Colorectal, March 28, Ouachita Parish Health Unit\n",
    "    Baton Rouge - Breast and Colorectal, March 30, Exxon Mobile YMCA\n",
    "    Houma - Breast, Prostate and Colorectal, March 31, Best Buy'''\n",
    "    output_10=\"1\"\n",
    "\n",
    "\n",
    "\n",
    "    Example_11='''Bi-State Regional Commission is hosting a transit summit and wants your input! Everyone is encouraged to complete this survey and/or attend a public meeting on Thursday 6/23 in Davenport from 4:00-6:00 p.m. Please complete the survey here, https://buff.ly/3xuaBsU'''\n",
    "    output_11=\"2\"\n",
    "\n",
    "\n",
    "\n",
    "    Example_12='''-\tCHRONIC DISEASE SELF-MANAGEMENT WORKSHOP hosted by: Independent Living Center of Southeast Missouri & University of Missouri Extension Registering now for the Spring 2023 class at the Doniphan location NO CHARGE!!!! Classes meet one time a week for six weeks â€¦..Approx. 2 Â½ hrs. Class size is limited.  â€¢ Living a Healthy Life is a FREE six-week workshop for adults living with chronic conditions and their family members, thanks to federal grant funding. â€¢ During this workshop you will learn how to:\n",
    "     - Identify the latest pain management approaches\n",
    "     - Manage fatigue and stress more effectively\n",
    "     - Find solutions to problems caused by your condition\n",
    "     - Identify ways to deal with anger, fear, frustration, anxiety and depression\n",
    "     - Discuss the role of exercise and nutrition in chronic disease management â€¢ How to Communicate with family and friends\n",
    "     - Form a partnership with your health-care team\n",
    "     Please pre-register by calling Suzann McKnight at ILCSEMO   573-686-2333  Ext. 222 or John Fuller at Mo. University of Extension Center 573-686-8064.\n",
    "     '''\n",
    "    \n",
    "\n",
    "    output_12='1'\n",
    "\n",
    "    Example_13='''-\tThe agreement provides many admissions advantages and options for students to transfer up to 8 credits from their undergraduate coursework to satisfy specific course requirements for the MSEP program'''\n",
    "    output_13='2'\n",
    "\n",
    "    Example_14='''-\tScrambling to pick up all your last minute Christmas meal groceries? Come shop with us this morning behind Pennington Biomedical from 8am - 12pm! You won't find any shopping cart traffic jams or long check out lines, just #farmfresh fruits and veggies, #localfood, sweet treats and smiling faces!'''\n",
    "    output_14='3'\n",
    "\n",
    "    Example_15='''-\tTonight at 6 PM! Join us virtually to provide your ideas on improving mobility within your communities in Miami-Dade County.\n",
    "    Learn about the Miami-Dade County New Mobility Initiative, a collaboration between Miami-Dade County Government, Urban Health Partnerships (UHP), Knight Foundation and Ford Motor Company's City:One program. The initiative aims to engage residents in the process of bringing new, innovative mobility solutions that can improve accessibility and equity in mobility for all County residents. \n",
    "    Register and learn more by visiting https://qrco.de/mdc1\n",
    "    #MDCNewMobility #MiamiDade #MiamiDadeCounty #Mobility #Transit #Transportation #Technology #Commute #Community #PublicHealth #Accessibility #Equity #HealthyStreets #PublicSpaces #UrbanHealth #UHP #Ford'''\n",
    "    \n",
    "    output_15='2'\n",
    "\n",
    "    Example_16='''-\tThe start of the school year has been amazing! And it has given us time to calculate the impact of our 2022 Summer.\n",
    "    176 Youth engaged in FYB Programs\n",
    "    Participating 2056:51 hours\n",
    "    145 bikes were earned and 112 Badges were earned.\n",
    "    15 interns had summer jobs through MYWE and FYB.\n",
    "    4 trip to YMCA Swim classes\n",
    "    16 bike rides\n",
    "    And memories that last a lifetime!\n",
    "    Thank you to all our students, parents, volunteers, and kind donors for making this happen. To learn how you can get involved go to frontyardbikes.com or email frontyardbikes@gmail.com\n",
    "    Special thanks to: @mayorbroome @bigbuddyprogram @line4linebr @kanobike @knockknockchildrensmuseum @blackbirdletterpress @threeoclockproject @youthcitylab_br'''\n",
    "\n",
    "    output_16='3'\n",
    "\n",
    "    # Build the messages exactly as you designed\n",
    "    prompt = f'''Now, classify the following post: {text}'''\n",
    "\n",
    "    pairs = [\n",
    "    ({\"role\":\"user\",\"content\": Example_1},  {\"role\":\"assistant\",\"content\": output_1}),\n",
    "    ({\"role\":\"user\",\"content\": Example_2},  {\"role\":\"assistant\",\"content\": output_2}),\n",
    "    ({\"role\":\"user\",\"content\": Example_3},  {\"role\":\"assistant\",\"content\": output_3}),\n",
    "    ({\"role\":\"user\",\"content\": Example_4},  {\"role\":\"assistant\",\"content\": output_4}),\n",
    "    ({\"role\":\"user\",\"content\": Example_5},  {\"role\":\"assistant\",\"content\": output_5}),\n",
    "    ({\"role\":\"user\",\"content\": Example_6},  {\"role\":\"assistant\",\"content\": output_6}),\n",
    "    ({\"role\":\"user\",\"content\": Example_7},  {\"role\":\"assistant\",\"content\": output_7}),\n",
    "    ({\"role\":\"user\",\"content\": Example_8},  {\"role\":\"assistant\",\"content\": output_8}),\n",
    "    ({\"role\":\"user\",\"content\": Example_9},  {\"role\":\"assistant\",\"content\": output_9}),\n",
    "    ({\"role\":\"user\",\"content\": Example_10}, {\"role\":\"assistant\",\"content\": output_10}),\n",
    "    ({\"role\":\"user\",\"content\": Example_11}, {\"role\":\"assistant\",\"content\": output_11}),\n",
    "    ({\"role\":\"user\",\"content\": Example_12}, {\"role\":\"assistant\",\"content\": output_12}),\n",
    "    ({\"role\":\"user\",\"content\": Example_13}, {\"role\":\"assistant\",\"content\": output_13}),\n",
    "    ({\"role\":\"user\",\"content\": Example_14}, {\"role\":\"assistant\",\"content\": output_14}),\n",
    "    ({\"role\":\"user\",\"content\": Example_15}, {\"role\":\"assistant\",\"content\": output_15}),\n",
    "    ({\"role\":\"user\",\"content\": Example_16}, {\"role\":\"assistant\",\"content\": output_16}),\n",
    "    ]\n",
    "    random.seed(42)  \n",
    "    random.shuffle(pairs)\n",
    "    message = [\n",
    "        {\"role\":\"system\",\"content\": system_message},\n",
    "        {\"role\":\"user\",\"content\": task_prompt},\n",
    "    ]\n",
    "    for u,a in pairs:\n",
    "        message.extend([u,a])\n",
    "    message.append({\"role\": \"user\", \"content\": prompt})\n",
    "    # Ensure pad token id is set (Qwen often uses eos as pad)\n",
    "    if pipe.tokenizer.pad_token_id is None:\n",
    "        pipe.tokenizer.pad_token_id = pipe.tokenizer.eos_token_id\n",
    "\n",
    "    # Convert chat messages to a single string using Qwen's chat template\n",
    "    chat_str = pipe.tokenizer.apply_chat_template(\n",
    "        message,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,  # model should start generating as assistant\n",
    "    )\n",
    "\n",
    "    # Model inference (greedy, 1 token)\n",
    "    outputs = pipe(\n",
    "        chat_str,\n",
    "        max_new_tokens=100,\n",
    "        do_sample=False,\n",
    "        temperature=0,\n",
    "        pad_token_id=pipe.tokenizer.pad_token_id,\n",
    "        eos_token_id=pipe.tokenizer.eos_token_id\n",
    "    )\n",
    "    #print(outputs)\n",
    "\n",
    "    # Pipeline returns a list of dicts; 'generated_text' is a string\n",
    "    gen = outputs[0][\"generated_text\"].strip()\n",
    "\n",
    "    # Extract the first digit 1-4; fallback to \"4\" if model slips\n",
    "    m = re.search(r\"[1234]\", gen)\n",
    "    label = m.group(0) if m else \"4\"\n",
    "\n",
    "#     gc.collect()\n",
    "#     if torch.cuda.is_available():\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "    return label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af0b4b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15751931d6b14206ae7040cc0b752778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4406427c674d8a9e49bcbf3584e447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.01` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\charl\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\integrations\\sdpa_attention.py:48: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    }
   ],
   "source": [
    "text = list(map(str, df[\"text\"]))\n",
    "# define the pipe\n",
    "pipe = instantiate_pipeline_qwen()\n",
    "# start a empty numpy array\n",
    "classifications = np.empty(len(text), dtype=object)\n",
    "\n",
    "# loop through and classify, saving every 100 iterations. \n",
    "for idx, i in tqdm_notebook(enumerate(text)):\n",
    "    classifications[idx] = classifier_qwen(i, pipe)\n",
    "    if (idx + 1) % 100 == 0:\n",
    "        \n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "df.to_csv(\"../../data/cleaned_data_with_classifications.csv.gz\", index=False, compression=\"gzip\")\n",
    "del text, pipe, classifications, df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
